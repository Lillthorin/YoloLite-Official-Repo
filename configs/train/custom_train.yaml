logging:
  log_dir: runs/train

loss:

  lambda_box: 5.0
  lambda_obj: 0.7        
  lambda_cls: 2.0        
  cls_smoothing: 0.0     
  topk_limit: 40          
  center_radius_cells: 2.5
  size_prior_w: 0.0       
  ar_prior_w: 0.0        

  focal_loss: false           
  center_radius: 2.5
  assign_cls_weight: 0.5
  focal: False
  gamma:  2
  alpha:  0.25
  area_cells_min:  4
  area_cells_max: 256
  area_tol:  1.25
  iou_cost_w:  3
  center_cost_w: 0.5

training:
  loss_type: simota           
  amp: true
  backbone_grad_scale: null
  batch_size: 8
  bb_lr_mult: 0.1
  ema: false
  epochs: 200
  freeze_backbone_epochs: 5
  grad_clip: 1.0
  head_lr_mult: 1.0
  lr: 1e-3
  neck_lr_mult: 1.0
  num_workers: 8
  optimizer: adamw
  save_every: 25
  scheduler: cosine
  seed: 1337
  warmup_epochs: 0
  weight_decay: 1e-4
  img_size: 640
  multi_scale_sizes: [320, 416, 512, 640]   
  augment: true
  use_p6: false
  resume:
  save_by: 
  pretrained: true
  


